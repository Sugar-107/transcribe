OpenAI:
  api_key: 'API_KEY'
  base_url: 'https://api.openai.com/v1'
# Possible model values
# gpt-4o, gpt-4o-2024-05-13
# gpt-4-turbo, gpt-4-turbo-2024-04-09, gpt-4, gpt-4-0613, gpt-4-32k, gpt-4-32k-0613
# gpt-3.5-turbo, gpt-3.5-turbo-16k, gpt-3.5-turbo-0613, gpt-3.5-turbo-16k-0613
# 
# Legacy models
# text-davinci-003, text-davinci-002, code-davinci-002
# See this link for available models
# https://platform.openai.com/docs/models/continuous-model-upgrades
  ai_model: gpt-4o
# Local model file to use for transcription.
# Can also be specified using the -m parameter on command line of the application
  local_transcripton_model_file: 'medium'
# Language in which ChatGPT should respond.
# List of languages available for openAI is available at
# https://platform.openai.com/docs/guides/speech-to-text/supported-languages
  response_lang: chinese
# Interpret the audio from speakers, mic to be in this language
  audio_lang: chinese

# Request timeout for any response requests made to openAI API
  response_request_timeout_seconds: 10

# Summarize request timeout for any response requests made to openAI API
  summarize_request_timeout_seconds: 30

# Temperature parameter for OpenAI chat completion API
  temperature: 0.0

Deepgram:
  api_key: 'API_KEY'

Together:
  api_key: 'API_KEY'
  # Supported models are at https://docs.together.ai/docs/inference-models
  ai_model: 'mistralai/Mixtral-8x7B-Instruct-v0.1'
  base_url: 'https://api.together.xyz'

WhisperCpp:
  # Can also be specified using the -m parameter on command line of the application
  local_transcripton_model_file: 'base'

General:
  log_file: 'logs/Transcribe.log'
  # These two parameters are used together.
  # Save LLM response to file if save_llm_response_to_file is Yes
  save_llm_response_to_file: Yes # Possible values are Yes, No
  llm_response_file: 'logs/response.txt'
# Attempt transcription of the sound file after these number of seconds
  transcript_audio_duration_seconds: 3
# These two parameters are used together.
# Setting clear_transcript_periodically: yes will clear transcript data at a regular interval
# clear_transcript_interval_seconds is applicable when clear_transcript_periodically is set to Yes
  clear_transcript_periodically: No # Possible values are Yes, No
  clear_transcript_interval_seconds: 90
# Determines whether to use API for STT or not. This option is applicable only for online services.
# This option has no affect on offline services.
# This is equivalent to -stt (speech_to_text) argument on command line.
# Command line argument takes precedence over value specified in parameters.yaml
  use_api: TRUE
# Index of microphone device. Value of -1 indicates it is not set.
# This is equivalent to -mi (mic_device_index) argument on command line
# Command line argument takes precedence over value specified in parameters.yaml
  mic_device_index: -1
# Index of speaker device.  Value of -1 indicates it is not set.
# This is equivalent to -si (speaker_device_index) argument on command line
# Command line argument takes precedence over value specified in parameters.yaml
  speaker_device_index: -1
# Disable Microphone
# This is equivalent to -dm (disable_mic) argument on command line
# Command line argument takes precedence over value specified in parameters.yaml
  disable_mic: False
# This is equivalent to -ds (disable_speaker) argument on command line
# Command line argument takes precedence over value specified in parameters.yaml
  disable_speaker: False
  stt: whisper
  continuous_response: True
  # The interval at which to ping the LLM for response
  llm_response_interval: 10

# This is equivalent to -c argument on command line
# Command line argument takes precedence over value specified in parameters.yaml
  chat_inference_provider: openai


# These are used for single turn, selected text responses only.
  default_prompt_preamble: "You are a casual pal, genuinely interested in the conversation at hand. A poor transcription of conversation is given below. "
  default_prompt_epilogue: "Please respond, in detail, to the conversation. Confidently give a straightforward response to the speaker, even if you don't understand them. Give your response in square brackets. DO NOT ask to repeat, and DO NOT ask for clarification. Just answer the speaker directly."
# The combination of system_prompt, initial_convo is used to create a multi turn prompt message for LLM.
# system_prompt_1, systen_prompt_2 are here as samples of other possible prompts.
# Only the content of system_prompt parameter will be used
  system_prompt: "Role: 高级Java专家和大数据技术专家 Background: 用户需要解决复杂的Java编程问题或大数据技术难题，期望得到专业的指导和解决方案。
  Profile: 您是一位在Java编程和大数据技术领域拥有深厚知识和丰富经验的专家。您对Java语言的高级特性、设计模式、性能优化以及大数据生态系统有深入理解。
  Skills: Java编程、大数据技术、分布式系统设计、性能调优、数据架构设计。
  Goals: 提供专业的Java技术的相关解决方案，解答大数据技术相关问题，分享最佳实践和行业趋势。不要提供代码示例！
  Constrains: 确保解决方案的准确性、高效性，同时考虑到可扩展性和维护性。 OutputFormat: 技术文档、代码示例、架构图、最佳实践指南。
Workflow:
  1. 理解用户的具体问题或需求。
  2. 分析问题的技术细节，考虑可能的解决方案。
  3. 提供详细的解答、代码示例或架构设计建议。
 Examples:
  问题：如何在Java中实现高效的内存管理？
  解答：使用Java的垃圾回收机制，例如G1收集器，来优化内存使用。考虑使用对象池来减少对象创建和销毁的开销。

  问题：如何处理大规模数据集的实时分析？
  解答：使用Apache Spark或Flink等流处理框架，结合Kafka等消息队列，实现数据的实时采集、处理和分析。
 Initialization: 欢迎使用高级Java专家和大数据技术专家服务。请告诉我您遇到的具体问题，我将为您提供专业的解决方案和建议。"
#  system_prompt: "You are an expert at Basketball and helping others learn about basketball. Please respond, in detail, to the conversation. Confidently give a straightforward response to the speaker, even if you don't understand them. Give your response in square brackets. DO NOT ask to repeat, and DO NOT ask for clarification. Just answer the speaker directly."
#  system_prompt: "You are an expert at Fantasy Football and helping others learn about Fantasy football. Please respond, in detail, to the conversation. Confidently give a straightforward response to the speaker, even if you don't understand them. Give your response in square brackets. DO NOT ask to repeat, and DO NOT ask for clarification. Just answer the speaker directly."
#  system_prompt: “You are an expert Agile Coach and are interviewing for a position. Respond in detail to the conversation. Confidently give a straightforward response to the speaker, even if you don't understand them. Give your response in square brackets. DO NOT ask to repeat, and DO NOT ask for clarification. Just answer the speaker directly."

  summary_prompt: 'Create a summary of the following text'

# When we anticipate to talk about a specific topic, seed the content with some conversation
# Application expects role "You" to have 1 entry
# If the conversation is generic, replace this text with something like this.
#   role: You
#   content: I am V, I want to have a casual friendly conversation
#   role: assistant
#   content: Hello V, That's awesome! Glad to meet you and I am looking forward to our conversation today
  initial_convo:
    first:
      role: "You"
      # content: "I am V, I want to learn about Fantasy Football"
      # content: "I am V, I want to learn about Basketball"
      # content: "Hey assistant, how are you doing today, I want to talk about Agile coaching today."
      content: "我是一个面试官，需要你提供给我考虑最完善，最细节的回答"
    second:
      role: "assistant"
      # content: "Hello, V. That's awesome! What do you want to know about basketball"
      # content: "Hello, V. That's awesome! What do you want to know about Fantasy Football"
      # content: "Hello, V. You are awesome. I am doing very well and looking forward to discussion about Agile coaching."
      content: "欢迎使用高级Java专家和大数据技术专家服务。请告诉我您遇到的具体问题，我将为您提供专业的解决方案和建议。"
